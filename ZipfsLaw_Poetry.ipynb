{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Zipf’s Law of Abbreviation applied to poetry\n",
        "# Author: Eva Florensa Villacampa"
      ],
      "metadata": {
        "id": "7rJs8JdoJ9Zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## OPENING THE URLs AND GETTING THE TEXT\n",
        "\n",
        "import urllib.request # Module for opening the URLs containing the books of poems\n",
        "\n",
        "# Dictionary with the URLs of the four books of poems: two in Catalan and two in English.\n",
        "book_urls = {\n",
        "    'eng1': 'https://www.gutenberg.org/cache/epub/48371/pg48371.txt',\n",
        "    'eng2': 'https://www.gutenberg.org/cache/epub/60337/pg60337.txt',\n",
        "    'cat1': 'https://www.gutenberg.org/cache/epub/52409/pg52409.txt',\n",
        "    'cat2': 'https://www.gutenberg.org/cache/epub/56866/pg56866.txt',\n",
        "}\n",
        "\n",
        "# Dictionary to keep the text of the books\n",
        "book_texts = {}\n",
        "\n",
        "# Loop to iterate through the dictionary: for each URL, get the text.\n",
        "for key, url in book_urls.items():\n",
        "  book_text = urllib.request.urlopen(url) # Open URL\n",
        "  book_text = book_text.read() # Read the content\n",
        "  book_text = book_text.decode(\"utf-8\") # Decode as UTF-8\n",
        "\n",
        "  # Keep the text in the dictionary\n",
        "  book_texts[key] = book_text\n",
        "\n",
        "# Access dictionary and save the text of each book in a different variable.\n",
        "eng1_text = book_texts.get('eng1', '')\n",
        "eng2_text = book_texts.get('eng2', '')\n",
        "cat1_text = book_texts.get('cat1', '')\n",
        "cat2_text = book_texts.get('cat2', '')"
      ],
      "metadata": {
        "id": "kQ9O24tE-xA1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## PRE-PROCESSING\n",
        "\n",
        "import re # Package to use regular expressions\n",
        "# Cleaning book eng1 by removing the information of the introduction and the end that is not part of the book\n",
        "eng1_cleaned = re.sub(\"^.*?British Library\", \"\", eng1_text, flags=re.DOTALL) # Substituting everything before British library with nothing, to cut what there was before. Use re.DOTALL to make the pattern match with multiple lines.\n",
        "eng1_cleaned = re.sub(\"END OF.*$\", \"\", eng1_cleaned, flags=re.DOTALL) # Susbtituting everythin after END OF with nothing, to cut it."
      ],
      "metadata": {
        "id": "Gz9l4U5ZzUji"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning book eng2, using the same procedure as with eng1.\n",
        "eng2_cleaned = re.sub(\"^.*?POEMS\", \"POEMS\", eng2_text, flags=re.DOTALL)\n",
        "eng2_cleaned = re.sub(\"End of Project.*$\", \"\", eng2_cleaned, flags=re.DOTALL)"
      ],
      "metadata": {
        "id": "24dd3skz1A9j"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning book cat1 by removing the English parts at the introduction and at the end, using the same procedure as with the English books.\n",
        "cat1_cleaned = re.sub(\"^.*?JOAN\", \"JOAN\", cat1_text, flags=re.DOTALL)\n",
        "cat1_cleaned = re.sub(\"END OF.*$\", \"\", cat1_cleaned, flags=re.DOTALL)"
      ],
      "metadata": {
        "id": "Ldg6ZNCAmCRY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning book cat2, using the same procedure as with cat1.\n",
        "cat2_cleaned = re.sub(\"^.*?JOAN\", \"JOAN\", cat2_text, flags=re.DOTALL)\n",
        "cat2_cleaned = re.sub(\"END OF.*$\", \"\", cat2_cleaned, flags=re.DOTALL)"
      ],
      "metadata": {
        "id": "xnnzONY3u0CN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all books, by splitting them at spaces\n",
        "eng1_tokenized = eng1_cleaned.split(\" \")\n",
        "eng2_tokenized = eng2_cleaned.split(\" \")\n",
        "cat1_tokenized = cat1_cleaned.split(\" \")\n",
        "cat2_tokenized = cat2_cleaned.split(\" \")"
      ],
      "metadata": {
        "id": "Vfl-ZhSsknc_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalization of the tokens to get more accurately the frequencies, without differences between uppercase and lowercase letters.\n",
        "eng1_normed = [w.lower() for w in eng1_tokenized]\n",
        "eng2_normed = [w.lower() for w in eng2_tokenized]\n",
        "cat1_normed = [w.lower() for w in cat1_tokenized]\n",
        "cat2_normed = [w.lower() for w in cat2_tokenized]"
      ],
      "metadata": {
        "id": "PFEWF2Mg7bGa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## COUNTING FREQUENCIES\n",
        "from collections import Counter # Importing the Counter from the collections library to count the number of occurrences of each word in the books.\n",
        "\n",
        "# Counting the frequencies and saving them into a variable for each book\n",
        "eng1_freq = Counter(eng1_normed)\n",
        "eng2_freq = Counter(eng2_normed)\n",
        "cat1_freq = Counter(cat1_normed)\n",
        "cat2_freq = Counter(cat2_normed)"
      ],
      "metadata": {
        "id": "p-4t2hb03AEV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for calculating the mean of the length of the words in a list.\n",
        "def mean_length(list_words):\n",
        "    total_letters = sum(len(word) for word, _ in list_words) # Adding the number of letters of each word in the list\n",
        "    total_words = len(list_words) # Counting the number of words in the list\n",
        "\n",
        "    mean = total_letters / total_words\n",
        "    return mean"
      ],
      "metadata": {
        "id": "tM9q0iEm6sTX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting and comparing the 10 most frequent words in the two English books.\n",
        "eng1_most_freq = eng1_freq.most_common(10)\n",
        "eng2_most_freq = eng2_freq.most_common(10)\n",
        "\n",
        "print(\"Most common words in English poems\")\n",
        "print(\"Eng1 book:\", eng1_most_freq)\n",
        "print(\"Eng2 book:\", eng2_most_freq)\n",
        "\n",
        "print(\"Average length of the words\")\n",
        "print(\"Eng1 book:\", mean_length(eng1_most_freq[1:])) # The index [1:] is included to avoid the first word, because it is empty.\n",
        "print(\"Eng2 book:\", mean_length(eng2_most_freq[1:]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSxYJmIhn_Dv",
        "outputId": "a28597be-381d-478d-94c5-8e90af205d92"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most common words in English poems\n",
            "Eng1 book: [('', 1942), ('the', 652), ('and', 404), ('of', 282), ('a', 166), ('that', 131), ('in', 129), ('to', 91), ('with', 75), ('is', 61)]\n",
            "Eng2 book: [('', 13693), ('the', 1568), ('and', 979), ('of', 823), ('a', 601), ('in', 465), ('to', 412), ('you', 254), ('i', 250), ('with', 219)]\n",
            "Average length of the words\n",
            "Eng1 book: 2.5555555555555554\n",
            "Eng2 book: 2.3333333333333335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting and comparing the 10 least frequent words in the two English books.\n",
        "eng1_least_freq = eng1_freq.most_common()[-11:-1] # Index used to obtain the 10 elements at the bottom, which are the least frequent words.\n",
        "eng2_least_freq = eng2_freq.most_common()[-11:-1]\n",
        "\n",
        "print(\"Least common words in English poems\")\n",
        "print(\"Eng1 book:\", eng1_least_freq)\n",
        "print(\"Eng2 book:\", eng2_least_freq)\n",
        "\n",
        "print(\"Average length of the words\")\n",
        "print(\"Eng1 book:\", mean_length(eng1_least_freq))\n",
        "print(\"Eng2 book:\", mean_length(eng2_least_freq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzSwEuwPo8XU",
        "outputId": "c7c25d68-a563-4cac-fdd7-e0bcd220ee53"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Least common words in English poems\n",
            "Eng1 book: [('――――\\r\\n\\r\\n', 1), ('_printed', 1), ('hazell,', 1), ('watson', 1), ('&', 1), ('viney,', 1), ('ld.,', 1), ('london', 1), ('aylesbury._\\r\\n\\r\\n\\r\\n', 1), ('\\r\\n', 1)]\n",
            "Eng2 book: [('sheep-faced', 1), ('ewe\\r\\n', 1), ('losing', 1), ('loosing', 1), ('lays', 1), ('anyone', 1), ('meat.\\r\\n', 1), ('ever\\r\\n', 1), ('egg,\\r\\n', 1), ('addled', 1)]\n",
            "Average length of the words\n",
            "Eng1 book: 6.5\n",
            "Eng2 book: 6.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting and comparing the 10 most frequent words in the two Catalan books.\n",
        "cat1_most_freq = cat1_freq.most_common(10)\n",
        "cat2_most_freq = cat2_freq.most_common(10)\n",
        "\n",
        "print(\"Most common words in Catalan poems\")\n",
        "print(\"Cat1 book:\", cat1_most_freq)\n",
        "print(\"Cat2 book:\", cat2_most_freq)\n",
        "\n",
        "print(\"Average length of the words\")\n",
        "print(\"Cat1 book:\", mean_length(cat1_most_freq[1:])) # The index [1:] is included to avoid the first word, because it is empty.\n",
        "print(\"Cat2 book:\", mean_length(cat2_most_freq[1:]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwKmkP75p462",
        "outputId": "07f03a7e-7a16-4a7f-c50a-5e71fa45be02"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most common words in Catalan poems\n",
            "Cat1 book: [('', 5713), ('la', 255), ('de', 233), ('i', 207), ('que', 174), ('el', 92), ('en', 88), ('a', 82), ('al', 66), ('els', 65)]\n",
            "Cat2 book: [('', 5794), ('la', 208), ('i', 196), ('que', 185), ('de', 173), ('les', 84), ('a', 84), ('el', 77), ('en', 64), ('del', 63)]\n",
            "Average length of the words\n",
            "Cat1 book: 2.0\n",
            "Cat2 book: 2.111111111111111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting and comparing the 10 least frequent words in the two Catalan books.\n",
        "cat1_least_freq = cat1_freq.most_common()[-11:-1] # Index used to obtain the 10 elements at the bottom, which are the least frequent words.\n",
        "cat2_least_freq = cat2_freq.most_common()[-11:-1]\n",
        "\n",
        "print(\"Least common words in Catalan poems\")\n",
        "print(\"Cat1 book:\", cat1_least_freq)\n",
        "print(\"Cat2 book:\", cat2_least_freq)\n",
        "\n",
        "print(\"Average length of the words\")\n",
        "print(\"Cat1 book:\", mean_length(cat1_least_freq))\n",
        "print(\"Cat2 book:\", mean_length(cat2_least_freq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCf6r5cqp4sp",
        "outputId": "ac74da4f-8da7-4bd4-be02-b61ebd6c3b0e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Least common words in Catalan poems\n",
            "Cat1 book: [('=joan', 1), ('sardà=,', 1), ('estudi', 1), ('necrologic.--1900.\\r\\n', 1), ('=visions', 1), ('&', 1), ('cants=', 1), ('(originals).--1900', 1), ('3\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n', 1), ('\\r\\n', 1)]\n",
            "Cat2 book: [('(1903).\\r\\n', 1), ('jacinto', 1), ('verdaguer,', 1), ('excursionista', 1), ('(1905).\\r\\n', 1), ('las', 1), ('reyals', 1), ('jornadas=', 1), ('(1904).\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n', 1), ('\\r\\n', 1)]\n",
            "Average length of the words\n",
            "Cat1 book: 8.8\n",
            "Cat2 book: 8.9\n"
          ]
        }
      ]
    }
  ]
}